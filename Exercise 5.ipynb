{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 5\n",
    "* Due: 11.2. at 14:00\n",
    "* Max points: 8"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## General rules\n",
    "* **Submit your answers by using Moodle.** The link is <a href=\"https://moodle.jyu.fi/course/view.php?id=11556\">https://moodle.jyu.fi/course/view.php?id=11556</a> and it can also be found in SISU.\n",
    "* Name your file as *lastname_ex5.xxx*. If you have multiple files, use *lastname_ex5_1.xxx, lastname_ex5_2.xxx* etc.\n",
    "* **Remember to add comments to your answers and include also some testing part!**\n",
    "* You will get feedback about your answers about a week from the due date\n",
    "* The exercises will be given on the previous Wednesday's lecture"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Exercises\n",
    "\n",
    "For exercises 1-2, we study optimization problem\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min \\qquad & x_1^2+x_2^2 + x_3^3+(1-x_4)^2\\\\\n",
    "\\text{s.t.}\\qquad &x_1^2+x_2^2-1=0\\\\\n",
    "    &x_1^2+x_3^2-1=0\\\\\n",
    "    &x\\in\\mathbb R^4\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "1. **(2 points)** Use the SQP method to solve the above problem. **Analyze carefully the result you got!** How does SQP work for this problem?\n",
    "2. **(2 points)** Use the augmented Lagrangian method to solve the above problem. **Analyze carefully the result you got!** How does the method work for this problem?\n",
    "3. **(2 points)** Solve the problem\n",
    "$$\n",
    "\\begin{align}\n",
    "\\min   \\  & x_1^2 + x_2^2\\\\\n",
    "\\text{s.t. } & x_1 + x_2 \\geq 1.\n",
    "\\end{align}$$ by using just the optimality conditions.\n",
    "4. **(2 points)** Consider a problem\n",
    "$$\\begin{align}\n",
    "\\min   \\  & f(x)\\\\\n",
    "\\text{s.t. } & h_k(x)=0, \\text{ for all } k=1,\\dots,K,\n",
    "\\end{align}\n",
    "$$\n",
    "\n",
    "where all the functions are twice differentiable. Show, that the *gradient of the augmented Lagrangian function* is zero in the minimizer $x^*$ of the above problem. In other words, show that $\\nabla_xL_c(x^*,\\lambda^*)=0$, where $\\lambda^*\\in R^n$ is the corresponding optimal Lagrange multiplier vector.\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
