{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "# Exercise 7, answers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 1"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part a)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Let's assume that a solution $x^*$ is an optimal solution to the achievement scalarizing problem, but it is not Pareto optimal. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "If $x^*$ is not Pareto optimal, then there exists $x'\\in S$ such that\n",
    "$$\n",
    "\\left\\{\n",
    "\\begin{align}\n",
    "f_i(x')\\leq f_i(x^*) \\text{ for all }i=1,\\ldots,k,\\text{ and}\\\\\n",
    "f_j(x')< f_j(x^*) \\text{ for some }j=1,\\ldots,k.\n",
    "\\end{align}\n",
    "\\right.\n",
    "$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,\n",
    "$$\n",
    "\\max_{i=1}^k(f_i(x^*)-z^{ref}_i)+\\rho\\sum_{i=1}^kf_i(x^*) \\geq \\max_{i=1}^k(f_i(x')-z^{ref}_i)+\\rho\\sum_{i=1}^kf_i(x^*)\\\\\n",
    ">  \\max_{i=1}^k(f_i(x')-z^{ref}_i)+\\rho\\sum_{i=1}^kf_i(x')\n",
    "$$\n",
    "where we used just the first inequality first, and then we used the previous proof from weighting method."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "This means again that if the solution $x^*$ is not Pareto optimal, then it cannot be an optimal solution to the achievement scalarizing function."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Part b)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Assume a Pareto optimal $x^*$. Now, we choose $z^{ref} = f(x^*)$. Let's have any solutions $x\\in S$. Then,\n",
    "$$\n",
    "\\max_{i=1\\ldots,k}(f_i(x)-z_i^{ref})+\\rho\\sum_{i=1}^kf_i(x) = \\max_{i=1\\ldots,k}(f_i(x)-f_i(x^*))\n",
    "\\geq 0,\n",
    "$$\n",
    "because $\\rho=0$ and $x^*$ is Pareto optimal and, thus, at least one of the objectives needs to be greater or equal (if this was not the case, the solution $x^*$ would not be Pareto optimal).\n",
    "\n",
    "But now,\n",
    "$$\n",
    "\\max_{i=1\\ldots,k}(f_i(x^*)-z_i^{ref})+\\rho\\sum_{i=1}^kf_i(x^*)= \\max_{i=1\\ldots,k}(f_i(x^*)-f_i(x^*))+\\rho\\sum_{i=1}^kf_i(x^*) \\\\\n",
    "= 0\n",
    "$$\n",
    "trivially. This means that the Pareto optimal solution $x^*$ is an optimal solution to the achievement scalarizing problem. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 4"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Using Pyomo, optimal solution is x*=(1,0,0)\n",
    "# x3 not in the constraints and because x1 => 0, we have x3=0\n",
    "# since x2**4 is always positive, x2=0\n",
    "# from the constraint it follows that x1**3 => 1 and we get x1=1\n",
    "\n",
    "from pyomo.environ import *\n",
    "\n",
    "model = ConcreteModel()\n",
    "#Three variables\n",
    "model.x = Var([1,2,3])\n",
    "#Objective function including powers and logarithm\n",
    "model.OBJ = Objective(expr = log(model.x[1]**2+1)+model.x[2]**4\n",
    "                      +model.x[1]*model.x[3]) #Objective function\n",
    "model.constr = Constraint(expr = model.x[1]**3-model.x[2]**2>=1)\n",
    "model.box1 = Constraint(expr = model.x[1]>=0)\n",
    "model.box2 = Constraint(expr = model.x[3]>=0)\n",
    "\n",
    "from pyomo.opt import SolverFactory #Import interfaces to solvers\n",
    "\n",
    "opt = SolverFactory(\"baron\") #Use baron\n",
    "\n",
    "res = opt.solve(model, tee=True) #Solve the  problem and print the output\n",
    "\n",
    "print(\"Optimal solutions is \")\n",
    "model.x.display()\n",
    "print(\"Objective value at the optimal solution is \")\n",
    "model.OBJ.display()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Let's try with Ipopt\n",
    "opt = SolverFactory(\"ipopt\") #Use ipopt\n",
    "\n",
    "res = opt.solve(model, tee=True) #Solve the  problem and print the output\n",
    "\n",
    "print(\"Optimal solutions is \")\n",
    "model.x.display()\n",
    "print(\"Objective value at the optimal solution is \")\n",
    "model.OBJ.display()\n",
    "\n",
    "# At least for me, Ipopt wa abel to solve the problem correctly but there was some i/o error when Pyomo was reading \n",
    "# the solution information that Ipopt had written in the output file. The solutions was correct."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Another way by a using penalty function method for comparison\n",
    "import numpy as np\n",
    "def f_constrained(x):\n",
    "    return np.log(x[0]**2+1)+x[1]**4+x[0]*x[2],[x[0]**3-x[1]**2-1,x[0],x[2]],[]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(x,f):\n",
    "    (_,ieq,eq) = f(x)\n",
    "    return sum([min([0,ieq_j])**2 for ieq_j in ieq])+sum([eq_k**2 for eq_k in eq])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def penalized_function(x,f,r):\n",
    "    return f(x)[0] + r*alpha(x,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from scipy.optimize import minimize\n",
    "r = 1\n",
    "# add multiple random starting points\n",
    "x_start = [-10,-3,-5]\n",
    "x_old = np.array([float('inf')]*3)\n",
    "x_new = x_start\n",
    "while np.linalg.norm(x_new-x_old)>0.000001:\n",
    "    res = minimize(lambda x:penalized_function(x,f_constrained,r),\n",
    "               x_start,method='Nelder-Mead')\n",
    "    x_old = x_new\n",
    "    x_new = np.array(res.x)\n",
    "    r = 2*r #r+1\n",
    "print(x_new, r)\n",
    "print(f_constrained(x_new))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Analysis:** Optimal solution is $x^*=(1,0,0)$ because\n",
    "* $x_3$ not in the constraints and because $x_1 \\geq 0$, we have $x_3=0$\n",
    "* since $x_2^4$ is always positive, $x_2=0$\n",
    "* from the constraint it follows that $x_1^3 \\geq 1$ and we get $x_1=1$\n",
    "\n",
    "*Based on the results, we can say that Baron was able to find a correct optimal solution. Also, the penalty function method found the same solution.*\n"
   ]
  }
 ],
 "metadata": {
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
