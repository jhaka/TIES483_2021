{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Exercise 4, answers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "outputs": [],
   "source": [
    "def f_constrained(x):\n",
    "    return x[0]**2+x[1]**2+x[0]+2*x[1], [], [x[0]+x[1]-1]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 1\n",
    "* max 2 points, 2 points if correct result is obtained, reductions for flaws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def alpha(x,f): # define penalty function\n",
    "    (_,ieq,eq) = f(x)\n",
    "    return sum([min([0,ieq_j])**2 for ieq_j in ieq])\\\n",
    "+sum([eq_k**2 for eq_k in eq])\n",
    "\n",
    "def penalized_function(x,f,r): # combine objective and penalty functions\n",
    "    return f(x)[0] + r*alpha(x,f)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let us solve the penalized problem with penalty term growin in a loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start = [0,0] # starting point\n",
    "\n",
    "import numpy as np\n",
    "from scipy.optimize import minimize\n",
    "r = 1 # initialize penalty parameter\n",
    "x_old = np.array([float('inf')]*2)\n",
    "x_new = start\n",
    "steps = []\n",
    "while np.linalg.norm(x_new-x_old)>0.0001: # stopping rule where the difference in the variable space is monitored\n",
    "    x_old = x_new\n",
    "    res = minimize(lambda x:penalized_function(x,f_constrained,r),\n",
    "               x_old,method='Nelder-Mead') # solve penalty problems by using Nelder Mead from scipy.optimize \n",
    "    x_new = np.array(res.x)\n",
    "    steps.append(list(x_new))\n",
    "#    r = r+1 # update penalty parameter; increase it with the penalty function\n",
    "    r = 10*r \n",
    "print(x_new, r) # print final solution and the final value of r\n",
    "print(len(steps)) # print number of steps"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "# plot steps\n",
    "def plot_2d_steps2(steps,start,interval):\n",
    "    myvec = np.array([start]+steps).transpose()\n",
    "    plt.plot(myvec[0,],myvec[1,],'rx')\n",
    "    for label,x,y in zip([str(i) for i in range(len(steps)+1)],myvec[0,],myvec[1,]):\n",
    "        plt.annotate(label,xy = (x, y))\n",
    "    # plot constraint\n",
    "    z = np.arange(interval[0],interval[1],0.1)\n",
    "    l = len(z)\n",
    "    con = [1.0-z[i] for i in range(l)]\n",
    "    plt.plot(z,con,'b-')\n",
    "    return plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = [-0.5,1.5]\n",
    "plot_2d_steps2(steps,start,interval).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 2\n",
    "* max 2 points, 2 points if correct result is obtained, reductions for flaws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Give slack for the equality constraint and convert it into two inequality constraints.\n",
    "# In this way, there are solutions inside the feasible region. Reduce slack when optimization progresses.\n",
    "def f_constrained_approx(x,epsilon):\n",
    "    return x[0]**2+x[1]**2+x[0]+2*x[1], [x[0]+x[1]-1+epsilon,\\\n",
    "                                         epsilon-(x[0]+x[1]-1)], []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# define barrier function\n",
    "def beta(x,f):\n",
    "    _,ieq,_ = f(x)\n",
    "    try:\n",
    "        value=sum([1/max([0,ieq_j]) for ieq_j in ieq])\n",
    "    except ZeroDivisionError: # handle dividion by zero\n",
    "        value = float(\"inf\")\n",
    "    return value\n",
    "\n",
    "# combine the objective and barrier functions\n",
    "def function_with_barrier(x,f,r):\n",
    "    return f(x)[0]+r*beta(x,f)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "start_b = [1,0] # feasible starting point\n",
    "\n",
    "import numpy as np\n",
    "import ad\n",
    "from scipy.optimize import minimize\n",
    "\n",
    "r = 1.0\n",
    "epsilon = 0.1 # initial slack for constraints\n",
    "x_old = np.array([float('inf')]*2)\n",
    "x_new = start_b\n",
    "steps_b = []\n",
    "while np.linalg.norm(x_new-x_old)>0.0001:\n",
    "    x_old = x_new\n",
    "    g = lambda x: function_with_barrier(x,\\\n",
    "               lambda y: f_constrained_approx(y,epsilon),r)\n",
    "#    res = minimize(g,x_old,method='Nelder-Mead')\n",
    "    res = minimize(g,x_old,method='Newton-CG',jac=ad.gh(g)[0],\\\n",
    "                   hess=ad.gh(g)[1])\n",
    "    x_new = res.x\n",
    "    steps_b.append(list(x_new))\n",
    "    r=r/2 # reduce penalty parameter\n",
    "    epsilon = epsilon/2 # reduce slack\n",
    "    print(x_new, f_constrained_approx(x_new,epsilon)[0], epsilon, r)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "interval = [0.6,1.2]\n",
    "plot_2d_steps2(steps_b,start_b,interval).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 3\n",
    "* max 2 points, 2 points if correct result is obtained, reductions for flaws"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "def project_vector(A,vector):\n",
    "    #convert A into a matrix\n",
    "    A_matrix = np.matrix(A)\n",
    "    #construct the \"first row\" of the matrix [[I,A^T],[A,0]]\n",
    "    left_matrix_first_row = np.concatenate((np.identity(len(vector)),A_matrix.transpose()), axis=1)\n",
    "    #construct the \"second row\" of the matrix\n",
    "    left_matrix_second_row = np.concatenate((A_matrix,np.matrix(np.zeros([len(A),len(A)]))), axis=1)\n",
    "    #combine the whole matrix by combining the rows\n",
    "    left_matrix = np.concatenate((left_matrix_first_row,left_matrix_second_row),axis = 0)\n",
    "    #Solve the system of linear equalities from the previous page\n",
    "    return np.linalg.solve(left_matrix, \\\n",
    "                           np.concatenate((np.matrix(vector).transpose(),\\\n",
    "                                           np.zeros([len(A),1])),axis=0))[:len(vector)]         "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import ad\n",
    "def projected_gradient_method(f,A,start,step,precision):\n",
    "    f_old = float('Inf')\n",
    "    x = np.array(start)\n",
    "    steps_p = []\n",
    "    f_new = f(x)\n",
    "    while abs(f_old-f_new)>precision:\n",
    "        f_old = f_new\n",
    "        gradient = ad.gh(f)[0](x)\n",
    "        grad_proj = project_vector(A,[-i for i in gradient])#The only changes to steepest..\n",
    "        grad_proj = np.array(grad_proj.transpose())[0] #... descent are here!\n",
    "        print(grad_proj)\n",
    "        x = x+grad_proj*step\n",
    "        f_new = f(x)\n",
    "        steps_p.append(list(x))\n",
    "    return x,f_new,steps_p"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "[x,f,s] = projected_gradient_method(lambda x:f_constrained(x)[0],[[1,1]],start_b\\\n",
    "                          ,.5,0.000001)\n",
    "print(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_2d_steps2(s,start_b,interval).show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "slideshow": {
     "slide_type": "slide"
    }
   },
   "source": [
    "## Task 4\n",
    "* max 2 points, 2 points if correct result is obtained, reductions for flaws"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Need to show that there exists unique Lagrance multiplier vectors $\\lambda^* = (\\lambda^*_1,\\ldots,\\lambda_J^*)$ and $\\mu^*=(\\mu_1^*,\\ldots,\\mu_K^*)$ such that\n",
    "$$\n",
    "\\begin{align}\n",
    "&\\nabla_xL(x,\\mu,\\lambda) = 0\\\\\n",
    "&\\mu_j^*\\geq0,\\text{ for all }j=1,\\ldots,J\\\\\n",
    "&\\mu_j^*g_j(x)=0,\\text{for all }j=1,\\ldots,J,\n",
    "\\end{align}\n",
    "$$\n",
    "where $$L(x,\\lambda,\\mu) = f(x)- \\sum_{k=1}^K\\mu_kg_k(x) -\\sum_{j=1}^J\\lambda_jh_j(x)$$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now,  $f(x) = x_1^2+x_2^2+x_1+2x_2$, $g(x) = 0$ and $h(x)=x_1+x_2-1$."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Thus, stationary rule becomes $$\n",
    "\\left\\{\n",
    "\\begin{align}\n",
    "2x_1+1-\\lambda = 0\\\\\n",
    "2x_2+2-\\lambda=0.\n",
    "\\end{align}\n",
    "\\right.\n",
    "$$\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We do not have a complementary rule, since we do not have inequality constraints!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Subroutine to check whether a given solution x satisfies the stationary rule with given tolerance.\n",
    "# In the equations above, we have l = 2x1 + 1 = 2x2 + 2. Multiplier l can thus have any real value.\n",
    "def check_KKT_eqc(x,tol):\n",
    "    l = 2*x[0]+1 # first equation above\n",
    "    print(2*x[1]+2-l)\n",
    "    if abs(2*x[1]+2-l)<=tol:\n",
    "        return True\n",
    "    return False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "check_KKT_eqc([1.0,0.0],0.000001)\n",
    "check_KKT_eqc([0.8,0.2],0.000001)\n",
    "check_KKT_eqc([0.74998093,0.24998093],0.000001)\n",
    "check_KKT_eqc([0.75,0.25],0.000001)"
   ]
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "celltoolbar": "Slideshow",
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
